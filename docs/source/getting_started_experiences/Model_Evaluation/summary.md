# Model Evaluation Getting Started Series Summary
This short series walks you through the essential steps for evaluating your computer vision models in FiftyOne — from computing metrics to visually inspecting performance and identifying areas for improvement.

## Summary of Steps
### Step 1: Basic Evaluation
In this step, you'll learn how to evaluate predictions against ground truth labels using FiftyOne’s built-in evaluation API. We'll walk through how to compute precision, recall, and other common metrics, and how to highlight false positives and false negatives directly in the app.

### Step 2: Analyzing with the Model Evaluation Panel
In the second step, you’ll explore FiftyOne’s interactive Model Evaluation Panel. This tool lets you sort samples by confidence, focus on edge cases like low-confidence predictions, and slice your dataset to pinpoint where your model struggles most.

## Next Steps

Now that you've completed the Detection Getting Started series, here are
some suggested next steps to deepen your journey with FiftyOne:

-   **Explore Mistake Detection**  
    Use [FiftyOne Brain](https://docs.voxel51.com/brain.html) to automatically detect potential labeling errors or overlapping bounding boxes in your dataset.

-   **Compare Multiple Models**
    Load predictions from multiple checkpoints or models and compare their evaluation results side-by-side.

-   **Connect with the Community**  
    Share your findings, ask questions, or browse community projects on the
    [FiftyOne Discord](https://community.voxel51.com) or
    [GitHub Discussions](https://tbd.com).

-   **Load Your Own Dataset**  
    Adapt these workflows to your real-world projects. Whether
    it's agriculture, retail, or industrial inspection — FiftyOne supports it
    all.

-   **Read the Docs**  
    Dive deeper into what FiftyOne can do in the
    [official documentation](https://docs.voxel51.com/).

We can't wait to see what you'll build next with FiftyOne!
